{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2J0ahkdl9JyIFenYO1W1s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Riturajkumari/Logistic_regression/blob/main/Logistic_Regression_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1. What is the purpose of grid search cv in machine learning, and how does it work?**"
      ],
      "metadata": {
        "id": "88q-PsNZDfW5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Grid search CV is used to train a machine learning model with multiple combinations of training hyperparameters and finds the best combination of parameters which optimizes the evaluation metric. \n",
        "-  It creates an exhaustive set of hyperparameter combinations and trains the model on each combination. The purpose of grid search CV is to find the best combination of hyperparameters that will give the best performance for a given model. "
      ],
      "metadata": {
        "id": "FbaDp2AxEh0N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-GridSearchCV is a technique for finding the optimal parameter values from a given set of parameters in a grid. It’s essentially a cross-validation technique. The model as well as the parameters must be entered. After extracting the best parameter values, predictions are made.\n",
        "   - GridSearchCV is the process of performing hyperparameter tuning in order to determine the optimal values for a given model."
      ],
      "metadata": {
        "id": "mUXrQZX8FMpD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nplRzg_1Dm5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2. Describe the difference between grid search cv and randomize search cv, and when might you choose\n",
        "one over the other?**"
      ],
      "metadata": {
        "id": "-BkWwDTSDnI2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Both GridSearchCV and RandomizedSearchCV are hyperparameter optimization techniques used in machine learning. \n",
        "- The main difference between them is that in GridSearchCV we try every combination of a preset list of values of the hyper-parameters and choose the best combination based on the cross-validation score.\n",
        "\n",
        "- Random search tries random combinations of a range of values (we have to define the number iterations). It is good at testing a wide range of values and normally it reaches a very good combination very fast, but the problem that it doesn’t guarantee to give the best parameter combination."
      ],
      "metadata": {
        "id": "2TNYxLOaGIWu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o9oiZWw3DuGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3.What is data leakage, and why is it a problem in machine learning? Provide an example.**"
      ],
      "metadata": {
        "id": "11FpzYbEDte8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Data leakage is a problem in machine learning when information from outside the training dataset is used to create the model. This can happen when there is a mistake in the way the data is split into training and testing sets, or when there is a leak of information from the test set into the training set.  \n",
        "- In its most basic form, data leakage happens when data ends up somewhere it’s not supposed to be. In machine learning, data leakage may cause overly optimistic or invalid predictive models. Data leaks can also cause significant data security issues when data that’s supposed to be protected, is instead exposed.\n",
        "\n",
        "   - For example, if you are building a model to predict whether an email is spam or not, and you include the email address as a feature in your model, then your model will be able to predict whether an email is spam or not based on the email address alone.\n"
      ],
      "metadata": {
        "id": "ND3dD74cIgqB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JMsv2PNKDyCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4. How can you prevent data leakage when building a machine learning model?**"
      ],
      "metadata": {
        "id": "u1dQb-0CDyN1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- To prevent data leakage in machine learning, it is important to carefully select features, perform proper data splitting, and avoid target leakage during data preprocessing.\n",
        "some tips for ensuring data leakage is prevented when using machine learning:\n",
        "\n",
        "- Ensure your data is secure and encrypted.\n",
        "- Implement a strong data governance policy.\n",
        "- Set up user authentication protocols.\n",
        "- Audit and monitor data access."
      ],
      "metadata": {
        "id": "l0u07EiUJKgm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. . Target leakage: This occurs when information from the target variable (i.e., the label being predicted) is inadvertently included in the training data. This can lead to overfitting and inflated performance metrics during training, as the model is effectively memorizing the training data instead of learning generalizable patterns.\n",
        "- Example: If a model is being trained to predict whether a customer will churn (i.e., cancel their subscription), and the training data includes information about whether the customer has already churned, this is target leakage."
      ],
      "metadata": {
        "id": "2cTLjuPqJwHW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l53L2-SbD7Dl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5. What is a confusion matrix, and what does it tell you about the performance of a classification model?**"
      ],
      "metadata": {
        "id": "ghW6STPDD7Yw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A confusion matrix is a matrix that summarizes the performance of a machine learning model on a set of test data. It is often used to measure the performance of classification models, which aim to predict a categorical label for each input instance. The matrix displays the number of true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN) produced by the model on the test data.\n",
        "\n",
        "- A Confusion matrix is an N x N matrix used for evaluating the performance of a classification model, where N is the number of target classes. The matrix compares the actual target values with those predicted by the machine learning model.\n",
        "\n",
        "a. A good model is one which has high TP and TN rates, while low FP and FN rates.\n",
        "b. If you have an imbalanced dataset to work with, it’s always better to use confusion matrix as your evaluation criteria for your machine learning model.\n"
      ],
      "metadata": {
        "id": "lEF6Lt1DLFNB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lnc1UOgCD_Mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q6. Explain the difference between precision and recall in the context of a confusion matrix.**"
      ],
      "metadata": {
        "id": "9-qyzvwoD_eQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- To calculate a model’s precision, we need the positive and negative numbers from the confusion matrix.\n",
        "\n",
        "Precision = TP/(TP + FP)"
      ],
      "metadata": {
        "id": "jfmjoyxoLqbr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Recall\n",
        "Recall goes another route. Instead of looking at the number of false positives the model predicted, recall looks at the number of false negatives that were thrown into the prediction mix.\n",
        "\n",
        "Recall = TP/(TP + FN)"
      ],
      "metadata": {
        "id": "ob6nzIq3LvCL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z4jrbyt7ED9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q7. How can you interpret a confusion matrix to determine which types of errors your model is making?**"
      ],
      "metadata": {
        "id": "x2fgfnlcEEJ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The confusion matrix shows the ways in which your classification model\n",
        "is confused when it makes predictions.\n",
        "\n",
        "It gives you insight not only into the errors being made by your classifier but more importantly the types of errors that are being made.\n",
        "\n",
        "It is this breakdown that overcomes the limitation of using classification accuracy alone."
      ],
      "metadata": {
        "id": "gAz9Sa9SMA3o"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6THI9r7EEHqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q8. What are some common metrics that can be derived from a confusion matrix, and how are they\n",
        "calculated?**"
      ],
      "metadata": {
        "id": "QuilBZPbEH41"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Confusion metrics are performance metrics for classification machine learning models. They are derived from the confusion matrix, which is a summary of the correct and incorrect predictions made by a model. The confusion matrix uses the values of True Positive, False Positive, True Negative, and False Negative to measure the model’s performance. "
      ],
      "metadata": {
        "id": "miEFVsyvMWsD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A confusion matrix has four components:\n",
        "\n",
        "- True positive (TP) - These are the correct predictions made that are labeled as positive. You can input this and the below values in the confusion matrix calculator's first section.\n",
        "- False negative (FN) - These are the wrong predictions made that are labeled as negative.\n",
        "- False positive (FP) - These are the wrong predictions made that are labeled as positive.\n",
        "- True negative (TN) - These are the correct predictions made that are labeled as negative."
      ],
      "metadata": {
        "id": "s8Uj3RavMjFc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SwReahXKELBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q9. What is the relationship between the accuracy of a model and the values in its confusion matrix?**"
      ],
      "metadata": {
        "id": "PGZTFE2kEMHu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- accuracy - Accuracy is the proportion of the correct predictions in the confusion matrix out of all predictions made. You can calculate accuracy from confusion matrix, as well as other metrics, using our tool."
      ],
      "metadata": {
        "id": "qxHFCh1IMxqD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Accuracy:  Accuracy is used to measure the performance of the model. It is the ratio of Total correct instances to the total instances.\n",
        "TP+TN/TP+FN+FP+TN \n",
        "\n"
      ],
      "metadata": {
        "id": "4cVRX0SWNTz3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o9phqG3oERbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q10. How can you use a confusion matrix to identify potential biases or limitations in your machine learning\n",
        "model?**"
      ],
      "metadata": {
        "id": "1pwrm2uGERnU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A confusion matrix is a summary of prediction results on a classification problem.\n",
        "\n",
        "The number of correct and incorrect predictions are summarized with count values and broken down by each class. This is the key to the confusion matrix.\n",
        "\n",
        "The confusion matrix shows the ways in which your classification model\n",
        "is confused when it makes predictions.\n",
        "\n",
        "It gives you insight not only into the errors being made by your classifier but more importantly the types of errors that are being made.\n",
        "\n",
        "It is this breakdown that overcomes the limitation of using classification accuracy alone.\n",
        "\n"
      ],
      "metadata": {
        "id": "gN52FOXxNtX1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*How to Calculate a Confusion Matrix*\n",
        "Below is the process for calculating a confusion Matrix.\n",
        "\n",
        "- You need a test dataset or a validation dataset with expected outcome values.\n",
        "- Make a prediction for each row in your test dataset.\n",
        "- From the expected outcomes and predictions count:\n",
        "- T-he number of correct predictions for each class."
      ],
      "metadata": {
        "id": "tqmbqsngODDI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ELXEMEyyEUJs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}